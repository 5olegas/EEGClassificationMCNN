{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a refactored version of a Multiscale Convolutional Network solution for NeuroHack at Yandex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.signal import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = \"hackaton_data/train.h5\"\n",
    "test_path = \"hackaton_data/test.h5\"\n",
    "model_dump_path = \"hackaton_data/convnet-multiscale-true-01988\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train data into a dict of (subject_id, (X, y)) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = {}\n",
    "with h5py.File(train_path, \"r\") as data_file:\n",
    "    for subject, subject_data in data_file.items():\n",
    "        X = subject_data[\"data\"][:]\n",
    "        y = subject_data[\"labels\"][:][0]\n",
    "        subjects[subject] = (X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility function to convert class labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_onehot(y):\n",
    "    onehot = np.zeros(3)\n",
    "    onehot[y] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a funtion that will select random subject and find a random subsequence of consistent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_slice(slice_len):\n",
    "    X, y = random.choice(list(subjects.values()))\n",
    "    X = X.T\n",
    "    while True:\n",
    "        slice_start = random.randint(0, len(X) - slice_len)\n",
    "        slice_end = slice_start + slice_len\n",
    "        slice_x = X[slice_start:slice_end]\n",
    "        slice_y = y[slice_start:slice_end]\n",
    "        \n",
    "        if len(set(slice_y)) == 1:\n",
    "            return slice_x, to_onehot(slice_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a generator that will yield batches of resampled input time series and according class labels in infinite loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size, slice_len):\n",
    "    while True:\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        for i in range(0, batch_size):\n",
    "            x, y = generate_slice(slice_len)\n",
    "            batch_x.append(x)\n",
    "            batch_y.append(y)\n",
    "            \n",
    "        y = np.array(batch_y)\n",
    "        \n",
    "        x_256 = np.array([resample(i, 256) for i in batch_x])\n",
    "        x_500 = np.array([resample(i, 500) for i in batch_x])\n",
    "        x = np.array([i for i in batch_x])\n",
    "        yield ([x_256, x_500, x], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build a neural network. Import all needed layers and keras utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution1D, Dense, Dropout, Input, merge, GlobalMaxPooling1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function builds a base neural net model that performs feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_base_model(input_len, fsize):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input_seq = Input(shape=(input_len, 24))\n",
    "    nb_filters = 150\n",
    "    convolved = Convolution1D(nb_filters, fsize, border_mode=\"same\", activation=\"tanh\")(input_seq)\n",
    "    processed = GlobalMaxPooling1D()(convolved)\n",
    "    compressed = Dense(150, activation=\"tanh\")(processed)\n",
    "    compressed = Dropout(0.3)(compressed)\n",
    "    compressed = Dense(150, activation=\"tanh\")(compressed)\n",
    "    model = Model(input=input_seq, output=compressed)            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slice_len = 1125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and compile a graph with 3 inputs and one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input256_seq = Input(shape=(256, 24))\n",
    "input500_seq = Input(shape=(500, 24))\n",
    "input1125_seq = Input(shape=(1125, 24))\n",
    "    \n",
    "base_network256 = get_base_model(256, 4)\n",
    "base_network500 = get_base_model(500, 7)\n",
    "base_network1125 = get_base_model(1125, 10)\n",
    "embedding_256 = base_network256(input256_seq)\n",
    "embedding_500 = base_network500(input500_seq)\n",
    "embedding_1125 = base_network256(input1125_seq)\n",
    "    \n",
    "merged = merge([embedding_256, embedding_500, embedding_1125], mode=\"concat\")\n",
    "out = Dense(3, activation='softmax')(merged)\n",
    "    \n",
    "model = Model(input=[input256_seq, input500_seq, input1125_seq], output=out)\n",
    "    \n",
    "opt = RMSprop(lr=0.005, clipvalue=10**6)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will train the model from scratch, lets load it from the model dump instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "nb_epoch = 100000\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
    "samples_per_epoch = 100000\n",
    "\n",
    "model.fit_generator(data_generator(batch_size=50, slice_len=slice_len), samples_per_epoch, nb_epoch, \n",
    "                    callbacks=[earlyStopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"hackaton_data/convnet-multiscale-true-01988\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 256, 24)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 500, 24)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (None, 1125, 24)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_5 (Model)                  (None, 100)           29900       input_7[0][0]                    \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_6 (Model)                  (None, 100)           37100       input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 300)           0           model_5[1][0]                    \n",
      "                                                                   model_6[1][0]                    \n",
      "                                                                   model_5[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 3)             903         merge_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 67,903\n",
      "Trainable params: 67,903\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read test data into a nested structure with multiple chunks for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"hackaton_data/test.h5\", \"r\") as data_file:\n",
    "    test = {}\n",
    "    for subject, subject_data in data_file.items():\n",
    "        test[subject] = {}\n",
    "        for chunk_id, chunk in data_file[subject].items():\n",
    "            test[subject][chunk_id] = chunk[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function that performs resampling of input timeseries \n",
    "def multiscale(chunk):\n",
    "    resampled_256 = resample(chunk, 256)\n",
    "    resampled_500 = resample(chunk, 500)\n",
    "    return [resampled_256, resampled_500, chunk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 79.41it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 214.76it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 213.29it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 178.24it/s]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for subj in test:\n",
    "    for chunk in tqdm(test[subj]):\n",
    "        data = {}\n",
    "        data[\"subject_id\"] = int(subj.split(\"_\")[-1])\n",
    "        data[\"chunk_id\"] = int(chunk.split(\"_\")[-1])\n",
    "        arr = test[subj][chunk].T\n",
    "        preds = model.predict([np.array([i]) for i in multiscale(arr)])[0]\n",
    "        data[\"class_0_score\"] = preds[0]\n",
    "        data[\"class_1_score\"] = preds[1]\n",
    "        data[\"class_2_score\"] = preds[2]\n",
    "        for i in range(0, 1125):\n",
    "            data[\"tick\"] = i\n",
    "            df.append(data.copy())\n",
    "df = pd.DataFrame(df)\n",
    "df = df[[\"subject_id\", \"chunk_id\", \"tick\", \"class_0_score\",\n",
    "         \"class_1_score\",\"class_2_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>tick</th>\n",
       "      <th>class_0_score</th>\n",
       "      <th>class_1_score</th>\n",
       "      <th>class_2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336646</td>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.517025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336646</td>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.517025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.336646</td>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.517025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0.336646</td>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.517025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0.336646</td>\n",
       "      <td>0.146329</td>\n",
       "      <td>0.517025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  chunk_id  tick  class_0_score  class_1_score  class_2_score\n",
       "0           2        31     0       0.336646       0.146329       0.517025\n",
       "1           2        31     1       0.336646       0.146329       0.517025\n",
       "2           2        31     2       0.336646       0.146329       0.517025\n",
       "3           2        31     3       0.336646       0.146329       0.517025\n",
       "4           2        31     4       0.336646       0.146329       0.517025"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save submission to .csv\n",
    "df.to_csv(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
